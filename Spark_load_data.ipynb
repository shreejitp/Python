{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step, in any Apache programming is to create a SparkContext. SparkContext is required when we want to execute operations in a cluster. SparkContext tells Spark how and where to access a cluster. And the first step is to connect with Apache Cluster. If you are using Spark Shell, you will notice that it is already created. Otherwise, we can create the SparkContext by importing, initializing and providing the configuration settings. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Sqlcontext \n",
    "from pyspark import SQLContext\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating DataFrame from RDD\n",
    "I am following these steps for creating a DataFrame from list of tuples:\n",
    "\n",
    "Create a list of tuples. Each tuple contains name of a person with age.\n",
    "Create a RDD from the list above.\n",
    "Convert each tuple to a row.\n",
    "Create a DataFrame by applying createDataFrame on RDD with the help of sqlContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "schemaPeople = sqlContext.createDataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(schemaPeople)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(1,2,3),(4,5,6),(7,8,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.toDF([\"a\",\"b\",\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  a|  b|  c|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "|  4|  5|  6|\n",
      "|  7|  8|  9|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([Row(a=1,b=2,c=3),Row(a=4,b=5,c=6),Row(a=7,b=8,c=9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  a|  b|  c|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "|  4|  5|  6|\n",
      "|  7|  8|  9|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://gokhanatil.com/2018/04/pyspark-examples-1-grouping-data-from-csv-file-using-rdds.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=sc.textFile(\"/Users/spillai/Downloads/user.txt\" ) \\\n",
    "    .map(lambda x: (x.split('|')[2],1) ) \\\n",
    "    .reduceByKey( lambda x,y:x+y ) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the CSV into a dataframe take the Movielens CSV file \n",
    "data = spark.read.format(\"csv\")\\\n",
    ".option(\"delimiter\", \";\")\\\n",
    ".option(\"header\", True)\\\n",
    ".load(\"/Users/spillai/Downloads/movielens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "|movieId|               title|              genres|userId|rating| timestamp|\n",
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|     7|   3.0| 851866703|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|    15|   2.0|1134521380|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|     5|   4.0|1163374957|\n",
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|               title|rating|\n",
      "+--------------------+------+\n",
      "|    Toy Story (1995)|   3.0|\n",
      "|      Jumanji (1995)|   2.0|\n",
      "|Grumpier Old Men ...|   4.0|\n",
      "+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"title\", \"rating\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "|movieId|               title|              genres|userId|rating| timestamp|\n",
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|    15|   2.0|1134521380|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|    15|   2.5|1093028381|\n",
      "|     14|        Nixon (1995)|               Drama|    15|   2.5|1166586286|\n",
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data['rating'] < 3.0).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|   0.5|  227|\n",
      "|   1.0|  574|\n",
      "+------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Group by Operation on the dataframe\n",
    "data.groupBy(data['rating']).count().orderBy('rating').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SQL to Query the dataframe. we need to register a DataFrame as a temp view\n",
    "data.createOrReplaceTempView(\"movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "|movieId|               title|              genres|userId|rating| timestamp|\n",
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|    15|   2.0|1134521380|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|    15|   2.5|1093028381|\n",
      "|     14|        Nixon (1995)|               Drama|    15|   2.5|1166586286|\n",
      "+-------+--------------------+--------------------+------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from movielens where rating < 3\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s create the DataFrame from RDD. We’ll use the same dataset, but this time will load it as a text file (also without a header). We want to keep only three columns for simplicity. So, load data into RDD, split by semicolon and select first three entries for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SparkContext First \n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"/Users/spillai/Downloads/movielens.txt\")\\\n",
    ".map(lambda line: line.split(\";\"))\\\n",
    ".map(lambda splits: (int(splits[0]), splits[1], splits[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy')\n",
      "(2, 'Jumanji (1995)', 'Adventure|Children|Fantasy')\n",
      "(3, 'Grumpier Old Men (1995)', 'Comedy|Romance')\n",
      "(4, 'Waiting to Exhale (1995)', 'Comedy|Drama|Romance')\n",
      "(5, 'Father of the Bride Part II (1995)', 'Comedy')\n"
     ]
    }
   ],
   "source": [
    "#Then, take a look at the contents of rdd\n",
    "for elem in rdd.take(5):\n",
    "   print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this moment, we import dependencies and create fields with specific types for the schema and as well as a schema itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "id_field = StructField(\"id\", IntegerType(), True)\n",
    "title_field = StructField(\"title\", StringType(), True)\n",
    "genres_field = StructField(\"genres\", StringType(), True)\n",
    "schema = StructType([id_field, title_field, genres_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               title|              genres|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|  2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|  3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movielens = spark.createDataFrame(rdd, schema)\n",
    "movielens.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading another movie Lens Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.textFile(\"/Users/spillai/Downloads/sample_movielens_ratings.txt\")\\\n",
    ".map(lambda line: line.split(\"::\"))\\\n",
    ".map(lambda splits: (int(splits[0]), int(splits[1]), float(splits[2]),int(splits[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2, 3.0, 1424380312)\n",
      "(0, 3, 1.0, 1424380312)\n",
      "(0, 5, 2.0, 1424380312)\n",
      "(0, 9, 4.0, 1424380312)\n",
      "(0, 11, 1.0, 1424380312)\n"
     ]
    }
   ],
   "source": [
    "#Then, take a look at the contents of rdd\n",
    "for elem in rdd2.take(5):\n",
    "   print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "userId_field = StructField(\"userId\", IntegerType(), True)\n",
    "movieId_field = StructField(\"movieId\", IntegerType(), True)\n",
    "rating_field = StructField(\"rating\", FloatType(), True)\n",
    "timestamp_field=StructField(\"timestamp\", LongType(), True)\n",
    "schema = StructType([userId_field, movieId_field,rating_field,timestamp_field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens2 = spark.createDataFrame(rdd2, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     0|      2|   3.0|1424380312|\n",
      "|     0|      3|   1.0|1424380312|\n",
      "+------+-------+------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movielens2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
